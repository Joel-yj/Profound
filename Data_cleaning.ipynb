{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from scholarly import scholarly \n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import os\n",
    "import csv\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Assignment1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Profound\\Data_cleaning.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Profound/Data_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mAssignment1.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32me:\\Python3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32me:\\Python3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32me:\\Python3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32me:\\Python3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32me:\\Python3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Assignment1.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Assignment1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DR-NTU URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the profile pictures of the professors\n",
    "\n",
    "os.chdir(\"dp\")\n",
    "\n",
    "count = 0\n",
    "for url in df['DR-NTU URL']:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    src = soup.find(class_ = 'image').find('img')['src']\n",
    "    src = src.replace(' ', '%20')\n",
    "    img_src = 'https://dr.ntu.edu.sg' + src\n",
    "    img = Image.open(requests.get(img_src,stream=True).raw)\n",
    "    img = img.convert('RGB')\n",
    "    img.save(str(count)+ '.jpg')\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the background / biography of the professors\n",
    "\n",
    "bio = []\n",
    "for url in df['DR-NTU URL']:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    c = soup.find(id = 'biographyDiv').text.replace('\\n', '')\n",
    "    bio.append(c)\n",
    "\n",
    "bio_df = pd.DataFrame(bio, columns = ['Biography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_df.to_csv('bio.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_interest = []\n",
    "profile_pic = []\n",
    "prof_name = []\n",
    "for names in df['Full Name']:\n",
    "    if names == \"Ke Yiping, Kelly\" :\n",
    "        names = names.replace(\"Ke Yiping, Kelly\", \"Ke Yiping\")\n",
    "    names = names + ', Nanyang Technological University'\n",
    "    search_query = scholarly.search_author(names)\n",
    "    try:\n",
    "        author = next(search_query)\n",
    "        if len(author['interests']) == 0:\n",
    "            research_interest.append(None)\n",
    "        else:\n",
    "            research_interest.append(author['interests'])\n",
    "        profile_pic.append(author['url_picture'])\n",
    "        prof_name.append(author['name'])\n",
    "        \n",
    "    except StopIteration:\n",
    "        research_interest.append(None)\n",
    "        profile_pic.append(None)\n",
    "        prof_name.append(None)\n",
    "\n",
    "new_df = pd.DataFrame({'Name': prof_name, 'Research Interest': research_interest, 'Profile Picture': profile_pic, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "df['Research Interest'] = test['Research Interest']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df = df[df['Research Interest'].isna()]\n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_interest = []\n",
    "for url in keywords_df['DR-NTU URL']:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    keyword_list = soup.find_all(class_ = 'rkeyword')\n",
    "    keywords = []\n",
    "    for item in keyword_list:\n",
    "        c = item.text.strip()\n",
    "        keywords.append(c)\n",
    "    research_interest.append(keywords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Research Interest'].fillna(research_interest, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting co-authors from dblp\n",
    "os.chdir(\"co_author\")\n",
    "\n",
    "\n",
    "count = 0\n",
    "for url in df['DBLP URL']:\n",
    "    names = []\n",
    "    href = []\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        co_author = soup.find_all(class_ = 'person')\n",
    "        for item in co_author:\n",
    "            names.append(item.text)\n",
    "            href.append(item.find('a')['href'])\n",
    "        pd.DataFrame(names,href).to_csv(str(count) + '.csv', header = False)\n",
    "    except:\n",
    "        print('No dblp page found for ' + str(url))\n",
    "    count+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to get the journals\n",
    "\n",
    "soup.find(id='coauthor-section').find_all('div')[9::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio = pd.read_csv('bio.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Assignment2.csv')\n",
    "df['Biography'] = bio['Biography']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Assignment2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.iterrows():\n",
    "    image_path = \"dp/\" + str(index) + \".jpg\"\n",
    "    print(image_path)\n",
    "Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.iterrows():\n",
    "    c = row['Research Interest']\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Research Interest'] = df['Research Interest'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Research Interest'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "\n",
    "search_query = scholarly.search_author('AS Madhukumar')\n",
    "author = next(search_query)\n",
    "c = scholarly.fill(author,sections = ['basics','counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savethis = c['cites_per_year']\n",
    "\n",
    "df = pd.DataFrame(list(savethis.items()), columns=['Year', 'Citations'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for prof's names on Google Scholar with NTU tag using Scholarly\n",
    "test_name = []\n",
    "test_citation = []\n",
    "test_affiliation = []\n",
    "\n",
    "citations = []\n",
    "for names in df['Full Name']:\n",
    "    if names == \"Ke Yiping, Kelly\" :\n",
    "        names = names.replace(\"Ke Yiping, Kelly\", \"Ke Yiping\")\n",
    "    if names == 'Li Fang':\n",
    "        continue\n",
    "    names = names + ', Nanyang Technological University'\n",
    "    search_query = scholarly.search_author(names)\n",
    "    try:\n",
    "        author = next(search_query)\n",
    "        \n",
    "        # Test DataFrame to check if the names and affiliation from Scholarly is correct.\n",
    "        test_name.append(author['name'])\n",
    "        test_citation.append(author['citedby'])\n",
    "        test_affiliation.append(author['affiliation'])\n",
    "\n",
    "        # Append the citations to the list\n",
    "        citations.append(author['citedby'])\n",
    "    except StopIteration:\n",
    "        citations.append(None)\n",
    "        # print(f\"Professor {names} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Assignment2.csv')\n",
    "\n",
    "os.chdir(\"citations\")\n",
    "for names in df['Full Name']:\n",
    "    if names == \"Ke Yiping, Kelly\" :\n",
    "        names = names.replace(\"Ke Yiping, Kelly\", \"Ke Yiping\")\n",
    "    if names == 'Li Fang':\n",
    "        continue\n",
    "    try:\n",
    "        names = names + ', Nanyang Technological University'\n",
    "        search_query = scholarly.search_author(names)\n",
    "        author = next(search_query)\n",
    "        c = scholarly.fill(author,sections = ['basics','counts'])\n",
    "        savethis = c['cites_per_year']\n",
    "        df = pd.DataFrame(list(savethis.items()), columns=['Year', 'Citations'])\n",
    "        df.to_csv(names + '.csv', index = False)\n",
    "    except:\n",
    "        print(f\"Professor {names} not found\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Assignment2.csv\")\n",
    "# df = df.iloc[0]\n",
    "df['Research Interest'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Research Interest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.loc[df['Full Name'] == 'Bo An'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('co_author/0.csv', header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Assignment2.csv')\n",
    "for i in range(86):\n",
    "    if i == 67:\n",
    "        continue\n",
    "    df = pd.read_csv('co_author/' + str(i) + '.csv', header = None)\n",
    "    for index1,row1 in df1.iterrows():\n",
    "        # print(row1['Full Name'])\n",
    "        G.add_node(row1['Full Name'])\n",
    "        for index,row in df.iterrows():\n",
    "            # print(row[1])\n",
    "            G.add_node(row[1])\n",
    "            # print(row1[\"Full Name\"], row[1])\n",
    "            G.add_edge(row1[\"Full Name\"], row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Assignment2.csv')\n",
    "scse_prof_names = df[\"Full Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('co_author/0.csv', header = None)\n",
    "co_author_names = df1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCSE Network\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('Assignment2.csv')\n",
    "faculty_names = df1['Full Name'].tolist()\n",
    "\n",
    "for name in faculty_names:\n",
    "    G.add_node(name)\n",
    "\n",
    "for i in range(86):\n",
    "    if i == 67:\n",
    "        continue\n",
    "    co_author_df = pd.read_csv('co_author/' + str(i) + '.csv', header = None)\n",
    "    current_prof = faculty_names[i]\n",
    "\n",
    "    for _,row in co_author_df.iterrows():\n",
    "        co_author_name = row[1]\n",
    "        if co_author_name in faculty_names:\n",
    "            G.add_edge(current_prof, co_author_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels=True, node_size=300, node_color='skyblue', font_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(G, with_labels=True, node_size=300, node_color='skyblue', font_size=10)\n",
    "\n",
    "# Display the graph\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_headers = [\n",
    "#     \"what\",\n",
    "#     \"Title\",\n",
    "#     \"Acronym\",\n",
    "#     \"Source\",\n",
    "#     \"Rank\",\n",
    "#     \"Note\",\n",
    "#     \"DBLP\",\n",
    "#     \"Primary FoR\",\n",
    "#     \"Comments\",\n",
    "#     \"Average Rating\"\n",
    "# ]\n",
    "\n",
    "# df = pd.read_csv(\"CORE.csv\", names=column_headers,)\n",
    "# df.drop(columns=[\"what\",\"Note\",\"DBLP\",\"Primary FoR\",\"Comments\",\"Average Rating\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CORE.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = pd.read_csv(\"publications/Arvind_Easwaran.csv\")\n",
    "prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof[prof['Journal Acronym'].isin(df['Acronym'].str.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df1 and df2 are your DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"CORE.csv\")\n",
    "prof = pd.read_csv(\"publications\\A_S_Madhukumar.csv\")\n",
    "\n",
    "# Convert col2 in df1 and col3 in df2 to lowercase (or uppercase)\n",
    "# df['Acronym'] = df['Acronym'].str.lower()\n",
    "\n",
    "# Create a boolean mask based on the condition\n",
    "condition = prof['Journal Acronym'].isin(df['Acronym'])\n",
    "\n",
    "# Use the boolean mask to filter rows in df1\n",
    "result_df = prof[condition]\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = df[df['Acronym'].isin(result_df['Journal Acronym'])]\n",
    "ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(result_df, ranking_df, left_on='Journal Acronym',right_on=\"Acronym\" ,how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor Chan Syin, Nanyang Technological University not found\n",
      "Professor Douglas Leslie Maskell, Nanyang Technological University not found\n",
      "Professor Jagath Chandana Rajapakse, Nanyang Technological University not found\n",
      "Professor Josephine Chong, Nanyang Technological University not found\n",
      "Professor Joty Shafiq Rayhan, Nanyang Technological University not found\n",
      "Professor Lau Chiew Tong, Nanyang Technological University not found\n",
      "Professor Li Mo, Nanyang Technological University not found\n",
      "Professor Luke Ong （翁之昊）, Nanyang Technological University not found\n",
      "Professor Pan, Sinno Jialin, Nanyang Technological University not found\n",
      "Professor Quek Hiok Chai, Nanyang Technological University not found\n",
      "Professor Sourav Saha Bhowmick, Nanyang Technological University not found\n",
      "Professor Tang Xueyan, Nanyang Technological University not found\n",
      "Professor Tay Kian Boon, Nanyang Technological University not found\n",
      "Professor Thambipillai Srikanthan, Nanyang Technological University not found\n",
      "Professor Vun Chan Hua, Nicholas, Nanyang Technological University not found\n",
      "Professor Wee Keong NG, Nanyang Technological University not found\n",
      "Professor Zinovi Rabinovich, Nanyang Technological University not found\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Assignment2.csv')\n",
    "\n",
    "os.chdir(\"indices\")\n",
    "for names in df['Full Name']:\n",
    "    if names == \"Ke Yiping, Kelly\" :\n",
    "        names = names.replace(\"Ke Yiping, Kelly\", \"Ke Yiping\")\n",
    "    if names == 'Li Fang':\n",
    "        continue\n",
    "    try:\n",
    "        names = names + ', Nanyang Technological University'\n",
    "        search_query = scholarly.search_author(names)\n",
    "        author = next(search_query)\n",
    "        c = scholarly.fill(author,sections = ['basics','indices'])\n",
    "        hindex = c['hindex']\n",
    "        hindex5y = c[\"hindex5y\"]\n",
    "        i10index = c['i10index']\n",
    "        i10index5y = c['i10index5y']\n",
    "        df = pd.DataFrame({\"hindex\":hindex, \"hindex5y\":hindex5y, \"i10index\":i10index, \"i10index5y\":i10index5y}, index = [0])\n",
    "        names.split(',')[0]\n",
    "        df.to_csv(names + '.csv', index = False)\n",
    "    except:\n",
    "        print(f\"Professor {names} not found\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = 'Bo An, Nanyang Technological University'\n",
    "search_query = scholarly.search_author(names)\n",
    "author = next(search_query)\n",
    "c = scholarly.fill(author,sections = ['basics','indices'])\n",
    "hindex = c['hindex']\n",
    "hindex5y = c[\"hindex5y\"]\n",
    "i10index = c['i10index']\n",
    "i10index5y = c['i10index5y']\n",
    "df = pd.DataFrame({\"hindex\":hindex, \"hindex5y\":hindex5y, \"i10index\":i10index, \"i10index5y\":i10index5y}, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.split(',')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Profound'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indices\\A S Madhukumar, Nanyang Technological University.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df.transpose()\n",
    "newdf.columns = ['Total']\n",
    "year_2018 = []\n",
    "year_2018.append(newdf.iloc[1][0])\n",
    "year_2018.append(newdf.iloc[3][0])\n",
    "newdf.drop([\"hindex5y\",\"i10index5y\"], inplace = True)\n",
    "newdf['2018'] = year_2018\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Column1': [1, 2, 3, 4],\n",
    "        'Column2': ['A', 'B', 'C', 'D']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Get the index of the second row (row at index 1)\n",
    "row_index = df.index[0]\n",
    "\n",
    "row_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
